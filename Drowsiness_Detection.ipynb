{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac003cf-84bc-42cb-bfe7-1af58b3fa0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the packages\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from playsound import playsound\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4c92bd0-009a-451e-ac2b-97afa70ec4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained eye model\n",
    "eye_model = tf.keras.models.load_model('eye_model.h5')\n",
    "\n",
    "# Haarcascades for face and eyes\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "# Dlib's face detector and landmark predictor\n",
    "hog_face_detector = dlib.get_frontal_face_detector()\n",
    "dlib_facelandmark = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df0acda-8d10-4af0-a5aa-37dac6be3501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict eye state\n",
    "def predict_eye_state(eye_image):\n",
    "    try:\n",
    "        eye_image = cv2.resize(eye_image, (64, 64))\n",
    "        eye_image = cv2.cvtColor(eye_image, cv2.COLOR_GRAY2RGB)\n",
    "        eye_image = eye_image / 255.0\n",
    "        eye_image = np.expand_dims(eye_image, axis=0)\n",
    "        prediction = eye_model.predict(eye_image, verbose=0)\n",
    "        return 'Closed' if prediction[0] < 0.5 else 'Open'\n",
    "    except:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Mouth aspect ratio for yawning\n",
    "def mouth_aspect_ratio(landmarks):\n",
    "    top_lip = landmarks.part(62).y\n",
    "    bottom_lip = landmarks.part(66).y\n",
    "    left_corner = landmarks.part(48).x\n",
    "    right_corner = landmarks.part(54).x\n",
    "    return (bottom_lip - top_lip) / (right_corner - left_corner)\n",
    "\n",
    "EYE_CLOSED_THRESHOLD_SEC = 5.0\n",
    "MAR_THRESHOLD = 0.4\n",
    "\n",
    "eye_closed_start_time = None\n",
    "is_drowsy = False\n",
    "alarm_on = False\n",
    "\n",
    "def play_alarm():\n",
    "    global alarm_on\n",
    "    if not alarm_on:\n",
    "        alarm_on = True\n",
    "        playsound(\"alarm.wav\")  # Replace with your sound file\n",
    "        alarm_on = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566fcb16-5534-4e32-bc74-6a89490140cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "    Error 263 for command:\n",
      "        close alarm.wav\n",
      "    The specified device is not open or is not recognized by MCI.\n",
      "Failed to close the file: alarm.wav\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Dlib for landmarks (mouth)\n",
    "    faces_dlib = hog_face_detector(gray)\n",
    "    yawn_detected = False\n",
    "    for face in faces_dlib:\n",
    "        landmarks = dlib_facelandmark(gray, face)\n",
    "        mar = mouth_aspect_ratio(landmarks)\n",
    "        \n",
    "        if mar > MAR_THRESHOLD:\n",
    "            yawn_detected = True\n",
    "            cv2.putText(frame, \"Yawning!\", (face.left(), face.top() - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    # Haar cascade for eyes\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "    eyes_closed = False\n",
    "    for (x, y, w, h) in faces:\n",
    "        roi_gray = gray[y:y + h, x:x + w]\n",
    "        roi_color = frame[y:y + h, x:x + w]\n",
    "\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "        for (ex, ey, ew, eh) in eyes:\n",
    "            eye_image = roi_gray[ey:ey + eh, ex:ex + ew]\n",
    "            eye_state = predict_eye_state(eye_image)\n",
    "\n",
    "            cv2.rectangle(roi_color, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
    "            cv2.putText(roi_color, f\"{eye_state}\", (ex, ey - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "\n",
    "            if eye_state == 'Closed':\n",
    "                eyes_closed = True\n",
    "\n",
    "    # Tracking eye closure duration\n",
    "    eye_closure_duration = 0\n",
    "    is_drowsy = False  # Reset drowsy flag each frame\n",
    "\n",
    "    if eyes_closed:\n",
    "        if eye_closed_start_time is None:\n",
    "            eye_closed_start_time = current_time\n",
    "        eye_closure_duration = current_time - eye_closed_start_time\n",
    "    else:\n",
    "        eye_closure_duration = 0\n",
    "        eye_closed_start_time = None\n",
    "\n",
    "    # Set drowsiness based on condition\n",
    "    if eye_closure_duration >= EYE_CLOSED_THRESHOLD_SEC or yawn_detected:\n",
    "        is_drowsy = True\n",
    "\n",
    "        cv2.putText(frame, \"DROWSY!!!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.2, (0, 0, 255), 3)\n",
    "        if not alarm_on:\n",
    "            threading.Thread(target=play_alarm).start()\n",
    "    else:\n",
    "        cv2.putText(frame, \"Awake\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1.2, (0, 255, 0), 2)\n",
    "        alarm_on = False\n",
    "\n",
    "    cv2.imshow(\"Drowsiness Detection\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d8295-b35f-4011-a273-253c6231f840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
